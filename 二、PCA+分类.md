## 二、PCA+分类

用PCA提取人脸图像的特征，分别用BP,RBF,SVM进行人脸识别，进行分析讨论，同时讨论对高斯白噪声的抑制能力。

### 1、仿真方法

#### 1.1 PCA提取人脸图像的特征:

因为第一题已经提过人脸图像的PCA，因此基础知识和PCA如何提取在此不再赘述。在此仅说明用于分类的数据。在这里为了保证PCA结果的稳定性和一致性，我在这里使用COVPCA即用协方差矩阵求取PCA结果，并且样本用一整幅图，即$112\times 92$pixel大小的向量进行PCA求取，由于本题的目标是提取特征，不是恢复图像，因此这样求取PCA可以更容易提取每幅图的特征。PCA结果取系数矩阵作为PCA提取的特征。

样本取法为将每幅

#### 1.2 加性高斯白噪声

与上次作业一样，此处加性高斯白噪声将加在整个样本上，使用matlab的awgn函数对样本加上高斯白噪声。

#### 1.3 分类结果的评价

分类器用trainingloss与testingloss来评价，两者计数均为分错类样本的个数：

记样本$i$的教师为$t_i$，结果为$y_i$
$$
\text{loss}=\sum _{i\in \{i|t_i \ne y_i\}}1
$$
也可以用失误率即lossrate来评价：

记一共有N个样本：
$$
\text{lossrate} = \frac{\text{loss}}{N}
$$

#### 1.4 结果展示

仿真结果主要以数据形式进行，由于分类结果会以序号的形式输出。

### 2. 分类方法

#### 2.1 BP网络分类

BP网络的基础知识在上一次已经提到过了，在此就不再赘述了。在这里，使用matlab的神经网络工具箱进行仿真。

##### 2.1.1 BP网络结构与设置

设置：


| 设置类型   | 值        |
| ------ | -------- |
| 迭代方法   | traingdx |
| 最大迭代次数 | 40000    |
| 误差限    | 1e-5     |
| 学习率    | 0.1      |

网络结构：

| 层数   | 网络类型    | 神经元数量 |
| ---- | ------- | ----- |
| 第一层  | purelin | 70    |
| 第二层  | tansig  | 40    |
| 输出层  | softmax | -     |

这里将最后一层改为softmax而不是sigmoid输出，原因是因为实测sigmoid输出分40类正确率只有5%左右，效果极低。因此在查阅相关文献以后将最后一层网络改为softmax。对应的教师用Onehot编码：

例如当$x^i$为第一类，则对应的教师$y^i=[1,0,0,0,\ldots,0]^T,y^i\in R^{40}$。即只有对应位置所在的值为1，其余为0。

###### Softmax简介

Softmax回归模型，是logistic回归模型在多分类问题上的推广。对于训练集$\{ (x^{(i)},y^{(i)} \},i=1,2,\ldots,m$，$y^{(i)} \in \{1,2,\ldots,k\}$。则对于给定的输入，我们的估计输出为：
$$
\begin{equation}
h_\theta(x^{(i)})=\left[
\begin{matrix}
p(y^{(i)}=1|x^{(i)};\theta) \\
p(y^{(i)}=2|x^{(i)};\theta) \\
\vdots\\
p(y^{(i)}=k|x^{(i)};\theta) 
\end{matrix}
\right]=\frac{1}{\sum_{j=1}^{k}e^{\theta_j^Tx(i)}}\left[
\begin{matrix}
e^{\theta_1^Tx(i)} \\
e^{\theta_2^Tx(i)} \\
\vdots\\
e^{\theta_k^Tx(i)} 
\end{matrix}
\right]
\end{equation}
$$
$\theta_j​$ 为模型的参数。上面的概率分布是归一化的，所有概率之和为1。

所以可以取估计输出的最大值为估计结果，即最有可能的类别。

##### 2.1.2 分类结果

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Trainingloss | Testingloss |
   | ------ | ------------ | ----------- |
   | 2      | 180          | 176         |
   | 5      | 115          | 134         |
   | 7      | 75           | 108         |
   | 10     | 49           | 64          |
   | 15     | 31           | 49          |
   | 20     | 21           | 36          |
   | 25     | 7            | 26          |
   | 30     | 5            | 22          |
   | 40     | 1            | 13          |
   | 50     | 0            | 14          |
   | 60     | 146          | 162         |
   | 80     | 148          | 173         |
   | 150    | 193          | 193         |
   | 200    | 191          | 190         |
   | 500    | 192          | 198         |
   ![BPpca主元](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\BPpca主元.png)

   可以看到，当PCA主元数取60以上的时候loss突然变高，这应该是由于随着PCA的主元数增加，网络对于输入样本来说太浅了，学习能力跟不上，因此产生了欠拟合。加深网络应该可以得到更好的效果。但是对于PCA主元少的时候，过深的网络会出现过拟合问题，所以实际上，网络深度要跟据当前的主元数进行设计。

   比如将网络结构改为下面的结构时：

   | 层数   | 网络类型    | 神经元数量 |
   | ---- | ------- | ----- |
   | 第一层  | purelin | 90    |
   | 第二层  | tansig  | 50    |
   | 第三层  | tansig  | 40    |
   | 输出层  | softmax | -     |

   trainingloss为10，testingloss为95。当然此时还存在有过拟合，但是此时已经比

2. 高斯白噪声的影响

   这里，训练集与测试集各一半，即用200张训练，200张测试，PCA主元取50个。分类结果如下表：

   | 高斯白噪声(SNR) | Trainingloss | Testingloss |
   | ---------- | ------------ | ----------- |
   | 2          | 197          | 193         |
   | 5          | 197          | 196         |
   | 7          | 199          | 196         |
   | 10         | 186          | 190         |
   | 15         | 116          | 130         |
   | 20         | 76           | 108         |
   | 25         | 0            | 13          |
   | 30         | 20           | 36          |
   | 40         | 18           | 35          |
   | 50         | 0            | 14          |
   | 60         | 0            | 14          |
   | 80         | 0            | 14          |

   ![BPLOSSSNR](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\BPLOSSSNR.png)

3. 训练集数量的影响

   这里依旧取50个主元，无高斯白噪声。

   | 训练集数量 | Traininglossrate | Testinglossrate |
   | ----- | ---------------- | --------------- |
   | 100   | 0                | 0.9333          |
   | 200   | 0                | 0.5625          |
   | 300   | 0                | 0.4607          |
   | 400   | 0                | 0.2958          |
   | 500   | 0                | 0.2300          |
   | 600   | 0                | 0.0438          |
   | 700   | 0                | 0.0417          |
   | 800   | 0                | 0.0375          |
   | 900   | 0                | 0.0500          |



#### 2.2 RBF网络分类

RBF网络的基础知识在上一次已经提到过了，在此就不再赘述了。在这里，使用matlab的神经网络工具箱进行仿真。Label与BP一样采用Onehot编码。

##### 2.2.1 网络参数设置：

RBF分类网络使用newbfe函数进行设计，要对newbfe的扩散系数进行设置，如用默认的1，则分类准确率低于5%。

取PCA50个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为8时，loss最低：

![RBF分类扩散系数影响](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类扩散系数影响.png)

取PCA500个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为17时，loss最低：

![RBF分类扩散系数影响1](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类扩散系数影响1.png)

取PCA20个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为9时，loss最低：

![RBF分类扩散系数影响2](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类扩散系数影响2.png)



所以，综合上述测试，下面测试全部取扩散系数为12。

##### 2.2.2 分类结果 

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Trainingloss | Testingloss |
   | ------ | ------------ | ----------- |
   | 2      | 70           | 126         |
   | 5      | 0            | 97          |
   | 7      | 0            | 107         |
   | 10     | 0            | 43          |
   | 15     | 0            | 13          |
   | 20     | 0            | 15          |
   | 25     | 0            | 10          |
   | 30     | 0            | 9           |
   | 40     | 0            | 8           |
   | 50     | 0            | 9           |
   | 60     | 0            | 9           |
   | 80     | 0            | 7           |
   | 150    | 0            | 7           |
   | 200    | 0            | 7           |
   | 500    | 0            | 7           |

   ![RBF分类pca主元](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类pca主元.png)

   ​

2. 高斯白噪声的影响：

   | 高斯白噪声(SNR) | Trainingloss | Testingloss |
   | ---------- | ------------ | ----------- |
   | 2          | 0            | 195         |
   | 5          | 0            | 192         |
   | 7          | 0            | 124         |
   | 10         | 0            | 21          |
   | 15         | 0            | 8           |
   | 20         | 0            | 9           |
   | 25         | 0            | 9           |
   | 30         | 0            | 9           |
   | 40         | 0            | 9           |
   | 50         | 0            | 9           |
   | 60         | 0            | 9           |
   | 80         | 0            | 9           |

   ![RBF分类白噪声](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类白噪声.png)

3. 训练集数量的影响：

   | 训练集数量 | Traininglossrate | Testinglossrate |
   | ----- | ---------------- | --------------- |
   | 100   | 0                | 0.3806          |
   | 200   | 0                | 0.2281          |
   | 300   | 0                | 0.1321          |
   | 400   | 0                | 0.0917          |
   | 500   | 0                | 0.0800          |
   | 600   | 0                | 0.0500          |
   | 700   | 0                | 0.0417          |
   | 800   | 0                | 0.0375          |
   | 900   | 0                | 0.0500          |

   ![RBF分类训练集数量](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\RBF分类训练集数量.png)

   ​


#### 2.3 SVM分类
##### 2.2.1 网络参数设置：



##### 2.2.2 分类结果 

由于这里使用的是高斯核函数，分类时总是可以达到对训练集的完美分类，因此，这里不列出trainingloss。

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Testingloss |
   | ------ | ----------- |
   | 2      | 126         |
   | 5      | 97          |
   | 7      | 107         |
   | 10     | 43          |
   | 15     | 13          |
   | 20     | 15          |
   | 25     | 10          |
   | 30     | 9           |
   | 40     | 8           |
   | 50     | 9           |
   | 60     | 9           |
   | 80     | 7           |
   | 150    | 7           |
   | 200    | 7           |
   | 500    | 7           |

2. 高斯白噪声的影响：

   | PCA主元数 | Testingloss |
   | ------ | ----------- |
   | 2      | 156         |
   | 5      | 127         |
   | 7      | 71          |
   | 10     | 54          |
   | 15     | 27          |
   | 20     | 13          |
   | 25     | 12          |
   | 30     | 12          |
   | 40     | 11          |
   | 50     | 11          |
   | 60     | 11          |
   | 80     | 11          |

   ![SVMpcaSNR](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\SVMpcaSNR.png)

3. 训练集数量的影响：

   | 训练集数 | Testinglossrate |
   | ---- | --------------- |
   | 100  | 0.2750          |
   | 200  | 0.3500          |
   | 300  | 0.3536          |
   | 400  | 0.2625          |
   | 500  | 0.2300          |
   | 600  | 0.1500          |
   | 700  | 0.1083          |
   | 800  | 0.0875          |
   | 900  | 0.0500          |

   ![SVMpca训练集](E:\17年学习\神经网络\神经网络作业二\NN_second_homework\PCA\SVMpca训练集.png)
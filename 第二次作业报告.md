# <center>神经网络第二次作业</center>

<center><small>学号：17210720048 姓名：俞钧昊</small></center>





## 一、PCA压缩

用两种PCA方法对人脸图像进行压缩，分别给出压缩比为50%，60%，70%，80%，90%，95%时，SNR是多少。更进一步，对两种PCA的求法进行比较分析

### 1. 基本原理

#### 1.1理论原理

对于给定的向量数据集，一般情况下，向量分量与分量之间存在高度的相关性，这表现在线性空间中，就是数据集大多数都分布在某个子空间附近，因此，对原始数据集的坐标轴进行旋转，得到新的坐标轴，在新的坐标轴中，数据的分布使得某些分量值更接近在0附近，从而其他维的信息可以作为该数据的估计。而这里的变换矩阵，从理论上来说，可以通过求协方差矩阵特征向量来获得，对于新坐标系中某些维的省略，构成了PCA压缩的原理，这也是PCA算法一种几何解释。如下图所示，向量$\mathbf{F_1,F_2}$就是这些数据的两个主元。

![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1513530189273&di=bb74418eeee6ef53cfb7ff87f9bf74bf&imgtype=0&src=http%3A%2F%2Fimages.cnitblog.com%2Fi%2F333250%2F201405%2F251755055126834.x-png)

PCA本质上是一个基替换的过程，假设元数据$\mathbf{x}^p\in R^n$，变换后的数据$\mathbf{y}^p\in R^m$。其目的是找到$m$个基，$m<n$。使得投影后的数据误差最小。

因此，记新的一组正交基为：$\mathbf{u}_1,\mathbf{u}_2,\ldots,\mathbf{u}_n$。则
$$
\mathbf{x}^p=\sum_{k=1}^n a_k^p \mathbf{u}_k
$$
$a_i^p$为$\mathbf{u}_i$上的投影系数。取其中的$m$个基：
$$
\mathbf{ \tilde{x}}^p = \sum_{i=1}^m a_k^p\mathbf{u}_i
$$
则目标即是：
$$
\min E=\frac{1}{2}\sum_{p=1}^N(\mathbf{x}^p-\mathbf{\tilde x})^T(\mathbf{x}^p-\mathbf{\tilde x})=  \\
E=\frac{N}{2}\sum_{i=m+1}^{n}\mathbf{u}_i^T \mathbf{C}_x \mathbf{u}_i
$$
所以，当$\mathbf{u}_i$为协方差矩阵$\mathbf{C}_x$的特征向量时：
$$
E=\frac{N}{2}\sum_{i=m+1}^{n}\mathbf{u}_i^T \lambda_i\mathbf{u}_i\\
E=\frac{N}{2}\sum_{i=m+1}^{n}\lambda_i(\mathbf{u}_i^T\mathbf{u}_i)
$$
所以当取最大的$m$个特征值对应的特征向量时，E将最小。

#### 1.2 算法分类

##### 1.2.1 COVPCA

即用协方差矩阵的特征值来进行PCA，流程如下：

1. 向量数据集去均值$\mathbf{X} = \mathbf{X}-E\{\mathbf{X}\}$
2. 求协方差矩阵$Cov(\mathbf{X}) = E\{\mathbf{X}\mathbf{X}^T\}$
3. 求取协方差矩阵的特征值和特征向量。保留前$m$个最大特征值以及对应的特征向量$\mathbf{u}_{\max i},i=1,\dots,m$
4. 得到$y_i^p=(\mathbf{x}^p)^T\mathbf{u}_{\max i}$

可以预想到，这种方法在协方差矩阵维数小时会很快，但是当协方差矩阵维数很大时，会出现维数灾难，大大增加计算量，使得非常耗时。当然，当样本数和样本长有一个较小时，可以用对样本矩阵先转置再求解的方法来处理，这样会大大减少运算量，因为两个协方差矩阵的特征值是一致的。

##### 1.2.2 CCIPCA(Candid Covariance Free Incremental PCA)

在协方差PCA方法中，计算协方差是唯一在实际操作中比较困难的方法。由于我们对于统计量，可以采用步进的方法实现，当输入的样本数量足够多，且样本的统计特性比较稳定的时候，步进的方式得到的协方差可以趋于真实数据的协方差。在该思路的基础上，提出了CCFIPCA的算法。

首先是对于第一个主元的收敛。若在某次迭代后，$\mathbf{w}(t)$趋于对应最大特征值的特征向量的倍数，即$\mathbf{w}(t)=\lambda\mathbf{u}_i$，其中$\lambda$为特征值，则由特征值特征向量的定义，有：
$$
\mathbf{w}(t)=\frac{1}{t}\sum_{i=1}^t\mathbf{x}^i{\mathbf{x}^i}^T \frac{\mathbf{w}(t-1)}{\Vert\mathbf{w}(t-1)\Vert}
$$
当$\mathbf{w}(t)$稳定时，由上式可以得到迭代公式：
$$
\mathbf{w}(t)=\frac{t-1}{t}\mathbf{w}(t-1)+\frac{1}{t}\mathbf{x}(t)\mathbf{x}(t)^T \frac{\mathbf{w(t-1)}}{\Vert\mathbf{\mathbf{w}(t-1)} \Vert}
$$
所以当$\mathbf{w}(t)$收敛后，归一化即可得到最大特征值对应的特征向量，然后将原数据减去该方向上的投影，即：
$$
\mathbf{x}=\mathbf{x}-\frac{\mathbf{x}^T\mathbf{w}}{\Vert\mathbf{w}\Vert}\cdot\frac{\mathbf{w}}{\Vert\mathbf{w}\Vert}
$$
之后对于去除第一主元的样本再用上述方法可以求取次大的特征值所对的特征向量。而实际操作中减去主分量的步骤可以穿插在每一步迭代中进行。

### 2. 仿真方法

#### 2.1 压缩比和PCA主元数

压缩比又称为压缩率，PCA压缩的计算方法如下：

记主元个数为$m$，主元长度为$l$，样本个数为$n$，则，压缩比$P$为：
$$
P=\frac{l\times m+m\times n}{n \times l}
$$
也有将压缩比记为被压缩数据量与原数据量的比值，即为$1-P$， 在这里，我采用上面的说法，出于完整性考虑，在列表时也会列出10%-90%的PSNR值，但出于篇幅考虑，仅放少部分图片。

所以主元数与其他参数的关系为：
$$
m = \frac{n\times l \times P}{n+l}
$$
在本例中，所有图像为：$92 \times 112$pixel大小，所以可以取每个主元长度为10304。按人进行压缩时，则每次有10个样本，则（无法达到95%压缩率，所以不列出）：

| 压缩率  | 主元个数m | 实际压缩率  |
| ---- | ----- | ------ |
| 10%  | 1     | 10.01% |
| 20%  | 2     | 20.02% |
| 30%  | 3     | 30.03% |
| 40%  | 4     | 40.04% |
| 50%  | 5     | 50.05% |
| 60%  | 6     | 60.06% |
| 70%  | 7     | 70.07% |
| 80%  | 8     | 80.08% |
| 90%  | 9     | 90.09% |

当以每行像素为样本时，则主元长度为92，按人进行压缩，则每次有1120个样本，则：

| 压缩比  | 主元个数m | 实际压缩率  |
| ---- | ----- | ------ |
| 5%   | 4     | 4.47%  |
| 10%  | 9     | 10.59% |
| 20%  | 17    | 20.00% |
| 30%  | 26    | 30.58% |
| 40%  | 34    | 39.99% |
| 50%  | 43    | 50.58% |
| 60%  | 51    | 59.99% |
| 70%  | 60    | 70.57% |
| 80%  | 68    | 80.00% |
| 90%  | 77    | 90.57% |
| 95%  | 81    | 95.28% |

以每列为样本时，主元长为112，按人进行压缩，则每次有920个样本，则：

| 压缩比  | 主元个数m | 实际压缩率  |
| ---- | ----- | ------ |
| 5%   | 5     | 5.02%  |
| 10%  | 10    | 10.04% |
| 20%  | 20    | 20.08% |
| 30%  | 30    | 30.12% |
| 40%  | 90    | 40.16% |
| 50%  | 50    | 50.08% |
| 60%  | 60    | 60.09% |
| 70%  | 70    | 70.11% |
| 80%  | 80    | 80.12% |
| 90%  | 90    | 90.14% |
| 95%  | 95    | 95.15% |

以每幅图的同一个像素作为样本，主元长为10，每次有10304个样本，则：

| 压缩比  | 主元个数m | 实际压缩率  |
| ---- | ----- | ------ |
| 10%  | 1     | 10.01% |
| 20%  | 2     | 20.02% |
| 30%  | 3     | 30.03% |
| 40%  | 4     | 40.04% |
| 50%  | 5     | 50.05% |
| 60%  | 6     | 60.06% |
| 70%  | 7     | 70.07% |
| 80%  | 8     | 80.08% |
| 90%  | 9     | 90.09% |

#### 3.2压缩图像评价标准：

##### 3.2.1 峰值信噪比PSNR

一般来说，对于压缩最直观也最常用的便是肉眼评价，但是这一方法具有一定的主观性，并且，对于微小差异无法给出评价。在此，我们使用峰值信噪比（PSNR）和压缩比进行评价，其中，峰值信噪比定义为：
$$
\text{PSNR} = 10\log _{10}(\frac{\text{MAX}_I^2}{\text{MSE}})
$$
$\text{MAX}_I$为图像点最大值，对于uint8的图像，$\text{MAX}_I=255$，$\text{MSE}$为均方误差：
$$
\text{MSE}=\frac{1}{MN}\sum_{i=1}^M\sum_{j=1}^N\Vert I(i,j)-\hat I(i,j) \Vert^2
$$
$I$为原始图像，$\hat I$为压缩后的图像。

### 3. 压缩结果

以下结果均以s1作为样本进行PSNR的分析：

#### 3.1 COVPCA

1. 按图像作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 10%  | 26.52    |
   | 20%  | 26.67    |
   | 30%  | 27.21    |
   | 40%  | 27.31    |
   | 50%  | 27.38    |
   | 60%  | 27.41    |
   | 70%  | 27.41    |
   | 80%  | 27.41    |
   | 90%  | 27.54    |

   ![COVPCApsnr1](PCA\COVPCApsnr1.png)

   测试结果：（为了节约篇幅，只放出10%，30%，50%，70%，90%的效果，左侧是原图，右图是压缩后的图片）

   10%：

   ![s1covpca对比SNR10](PCA\s1covpca对比SNR20.png)

   30%：

   ![s1covpca对比SNR30](PCA\s1covpca对比SNR30.png)

   50%：

   ![s1covpca对比SNR50](PCA\s1covpca对比SNR50.png)

   70%：

   ![s1covpca对比SNR70](PCA\s1covpca对比SNR70.png)

   90%：

   ![s1covpca对比SNR90](PCA\s1covpca对比SNR90.png)


1. 按列作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 5%   | 30.18    |
   | 10%  | 32.25    |
   | 20%  | 35.02    |
   | 30%  | 37.57    |
   | 40%  | 39.75    |
   | 50%  | 41.79    |
   | 60%  | 43.69    |
   | 70%  | 45.74    |
   | 80%  | 48.06    |
   | 90%  | 50.87    |
   | 95%  | 52.56    |

   ![CCIPCApsnr2](PCA\CCIPCApsnr2.png)

   10%:

   ![s1covpcablock对比SNR10](PCA\s1covpcablock对比SNR10.png)

   30%:

   ![s1covpcablock对比SNR30](PCA\s1covpcablock对比SNR30.png)

   50%：

   ![s1covpcablock对比SNR50](PCA\s1covpcablock对比SNR50.png)

   70%：

   ![s1covpcablock对比SNR70](PCA\s1covpcablock对比SNR70.png)

   90%：

   ![s1covpcablock对比SNR90](PCA\s1covpcablock对比SNR90.png)

2. 按像素作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 10%  | 29.55    |
   | 20%  | 29.69    |
   | 30%  | 30.62    |
   | 40%  | 31.21    |
   | 50%  | 32.00    |
   | 60%  | 33.15    |
   | 70%  | 34.76    |
   | 80%  | 37.65    |
   | 90%  | Inf      |

   ![COVPCApsnr3](PCA\COVPCApsnr3.png)

   10%:

   ![s1covpcapix对比SNR10](PCA\s1covpcapix对比SNR10.png)

   30%:

   ![s1covpcapix对比SNR30](PCA\s1covpcapix对比SNR30.png)

   50%：

   ![s1covpcapix对比SNR50](PCA\s1covpcapix对比SNR50.png)

   70%：

   ![s1covpcapix对比SNR70](PCA\s1covpcapix对比SNR70.png)

   90%：

   ![s1covpcapix对比SNR90](PCA\s1covpcapix对比SNR90.png)

#### 3.2 CCIPCA

1. 按图像作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 10%  | 28.84    |
   | 20%  | 29.22    |
   | 30%  | 29.70    |
   | 40%  | 30.15    |
   | 50%  | 30.66    |
   | 60%  | 30.98    |
   | 70%  | 32.07    |
   | 80%  | 33.07    |
   | 90%  | 34.79    |

   ![CCIPCApsnr1](PCA\CCIPCApsnr1.png)

   50%：

   ![s1ccipca对比SNR50](PCA\s1ccipca对比SNR50.png)

   70%：

   ![s1ccipca对比SNR70](PCA\s1ccipca对比SNR70.png)

   90%：

   ![s1ccipca对比SNR90](PCA\s1ccipca对比SNR90.png)

2. 按列作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 5%   | 30.47    |
   | 10%  | 32.13    |
   | 20%  | 33.79    |
   | 30%  | 35.10    |
   | 40%  | 36.05    |
   | 50%  | 37.39    |
   | 60%  | 38.69    |
   | 70%  | 40.10    |
   | 80%  | 42.06    |
   | 90%  | 44.14    |
   | 95%  | 45.49    |

   ![CCIPCApsnr2](PCA\CCIPCApsnr2.png)

   50%：

   ![s1ccipcablock对比SNR50](PCA\s1ccipcablock对比SNR50.png)

   70%：

   ![s1ccipcablock对比SNR70](PCA\s1ccipcablock对比SNR70.png)

   90%：

   ![s1ccipcablock对比SNR90](PCA\s1ccipcablock对比SNR90.png)

3. 按像素作为样本进行压缩：

   | 压缩比  | PSNR（db） |
   | ---- | -------- |
   | 10%  | 29.20    |
   | 20%  | 29.60    |
   | 30%  | 30.22    |
   | 40%  | 31.02    |
   | 50%  | 31.90    |
   | 60%  | 32.52    |
   | 70%  | 34.09    |
   | 80%  | 36.74    |
   | 90%  | Inf      |

   ![CCIPCApsnr3](PCA\CCIPCApsnr3.png)

   50%：

   ![s1ccipcapix对比SNR50](PCA\s1ccipcapix对比SNR50.png)

   70%：

   ![s1ccipcapix对比SNR70](PCA\s1ccipcapix对比SNR70.png)

   90%：

   ![s1ccipcapix对比SNR90](PCA\s1ccipcapix对比SNR90.png)

### 4. 总结

#### 4.1运行时间

在运行过程中，当不分块直接PCA时，COVPCA运算非常慢，但CCIPCA运算比较快，这主要是由于CCIPCA影响运行时间主要是样本个数，而COVPCA影响运算时间的主要是主元长度。当不分块时，样本数量小，因此CCIPCA比COVPCA快。但当分块或按像素进行压缩时，COVPCA要远快于CCIPCA。这也是因为此时，样本数量变大而主元长度变小。

#### 4.2 压缩效果

当不分块时，无论是从PSNR的数据还是从肉眼观察都可以看出，CCIPCA的效果要好于COVPCA，这可能是由于样本数较少，CCIPCA迭代并不完全收敛于最大特征向量处，反而会收敛于某几幅图相似图的叠加效果上，这反而使得压缩效果好于原来COVPCA。但是当用像素或用列作为主元时，COVPCA就好于CCIPCA。这是因为当取主元数足够多时，COVPCA才是最优的PCA结果，CCIPCA只是逼近COVPCA，这在理论上也是合理的。

而在压缩效果来说，用一幅图长度作为主元时，压缩率低时，可以看到恢复效果是很多人的脸的替加。随着压缩率上升，可以看到自己脸的轮廓变得清晰，但还是会有其他人脸的模轮廓。而用一列长度作为主元长度时，压缩率低时会有横条纹的效果。当用像素作为输入样本时，压缩率低时，图案会变得模糊。

同时，从PSNR可以看出，按列压缩取得的效果要好于另两者。这也说明了，用PCA压缩时，对主元长度或者说输入样本的选择很重要。但是总体来说，PCA在压缩率低的时候肉眼观察效果很差，相比较JPEG压缩要相差很多，因此PCA实际上不适合用于图像的压缩。



## 二、PCA+分类

用PCA提取人脸图像的特征，分别用BP,RBF,SVM进行人脸识别，进行分析讨论，同时讨论对高斯白噪声的抑制能力。

### 1、仿真方法

#### 1.1 PCA提取人脸图像的特征:

因为第一题已经提过人脸图像的PCA，因此基础知识和PCA如何提取在此不再赘述。在此仅说明用于分类的数据。在这里为了保证PCA结果的稳定性和一致性，我在这里使用COVPCA即用协方差矩阵求取PCA结果，并且样本用一整幅图，即$112\times 92$pixel大小的向量进行PCA求取，由于本题的目标是提取特征，不是恢复图像，因此这样求取PCA可以更容易提取每幅图的特征。PCA结果取系数矩阵作为PCA提取的特征。

样本取法为将每幅

#### 1.2 加性高斯白噪声

与上次作业一样，此处加性高斯白噪声将加在整个样本上，使用matlab的awgn函数对样本加上高斯白噪声。

#### 1.3 分类结果的评价

分类器用trainingloss与testingloss来评价，两者计数均为分错类样本的个数：

记样本$i$的教师为$t_i$，结果为$y_i$
$$
\text{loss}=\sum _{i\in \{i|t_i \ne y_i\}}1
$$
也可以用失误率即lossrate来评价：

记一共有N个样本：
$$
\text{lossrate} = \frac{\text{loss}}{N}
$$

#### 1.4 结果展示

仿真结果主要以数据形式进行，由于分类结果会以序号的形式输出。

### 2. 分类方法

#### 2.1 BP网络分类

BP网络的基础知识在上一次已经提到过了，在此就不再赘述了。在这里，使用matlab的神经网络工具箱进行仿真。

##### 2.1.1 BP网络结构与设置

设置：

| 设置类型   | 值        |
| ------ | -------- |
| 迭代方法   | traingdx |
| 最大迭代次数 | 40000    |
| 误差限    | 1e-5     |
| 学习率    | 0.1      |

网络结构：

| 层数   | 网络类型    | 神经元数量 |
| ---- | ------- | ----- |
| 第一层  | purelin | 70    |
| 第二层  | tansig  | 40    |
| 输出层  | softmax | -     |

这里将最后一层改为softmax而不是sigmoid输出，原因是因为实测sigmoid输出分40类正确率只有5%左右，效果极低。因此在查阅相关文献以后将最后一层网络改为softmax。对应的教师用Onehot编码：

例如当$x^i$为第一类，则对应的教师$y^i=[1,0,0,0,\ldots,0]^T,y^i\in R^{40}$。即只有对应位置所在的值为1，其余为0。

###### Softmax简介

Softmax回归模型，是logistic回归模型在多分类问题上的推广。对于训练集$\{ (x^{(i)},y^{(i)} \},i=1,2,\ldots,m$，$y^{(i)} \in \{1,2,\ldots,k\}$。则对于给定的输入，我们的估计输出为：
$$
\begin{equation}
h_\theta(x^{(i)})=\left[
\begin{matrix}
p(y^{(i)}=1|x^{(i)};\theta) \\
p(y^{(i)}=2|x^{(i)};\theta) \\
\vdots\\
p(y^{(i)}=k|x^{(i)};\theta) 
\end{matrix}
\right]=\frac{1}{\sum_{j=1}^{k}e^{\theta_j^Tx(i)}}\left[
\begin{matrix}
e^{\theta_1^Tx(i)} \\
e^{\theta_2^Tx(i)} \\
\vdots\\
e^{\theta_k^Tx(i)} 
\end{matrix}
\right]
\end{equation}
$$
$\theta_j$ 为模型的参数。上面的概率分布是归一化的，所有概率之和为1。

所以可以取估计输出的最大值为估计结果，即最有可能的类别。

##### 2.1.2 分类结果

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Trainingloss | Testingloss |
   | ------ | ------------ | ----------- |
   | 2      | 180          | 176         |
   | 5      | 115          | 134         |
   | 7      | 75           | 108         |
   | 10     | 49           | 64          |
   | 15     | 31           | 49          |
   | 20     | 21           | 36          |
   | 25     | 7            | 26          |
   | 30     | 5            | 22          |
   | 40     | 1            | 13          |
   | 50     | 0            | 14          |
   | 60     | 146          | 162         |
   | 80     | 148          | 173         |
   | 150    | 193          | 193         |
   | 200    | 191          | 190         |
   | 500    | 192          | 198         |

   ![BPpca主元](PCA\BPpca主元.png)

   可以看到，当PCA主元数取60以上的时候loss突然变高，这应该是由于随着PCA的主元数增加，网络对于输入样本来说太浅了，学习能力跟不上，因此产生了欠拟合。加深网络应该可以得到更好的效果。但是对于PCA主元少的时候，过深的网络会出现过拟合问题，所以实际上，网络深度要跟据当前的主元数进行设计。

   比如将网络结构改为下面的结构时：

   | 层数   | 网络类型    | 神经元数量 |
   | ---- | ------- | ----- |
   | 第一层  | purelin | 90    |
   | 第二层  | tansig  | 50    |
   | 第三层  | tansig  | 40    |
   | 输出层  | softmax | -     |

   trainingloss为10，testingloss为95。当然此时还存在有过拟合，但是此时已经比之前要好很多。

2. 高斯白噪声的影响

   这里，训练集与测试集各一半，即用200张训练，200张测试，PCA主元取50个。分类结果如下表：

   | 高斯白噪声(SNR) | Trainingloss | Testingloss |
   | ---------- | ------------ | ----------- |
   | 2          | 197          | 193         |
   | 5          | 197          | 196         |
   | 7          | 199          | 196         |
   | 10         | 186          | 190         |
   | 15         | 116          | 130         |
   | 20         | 76           | 108         |
   | 25         | 0            | 13          |
   | 30         | 20           | 36          |
   | 40         | 18           | 35          |
   | 50         | 0            | 14          |
   | 60         | 0            | 14          |
   | 80         | 0            | 14          |

   ![BPLOSSSNR](PCA\BPLOSSSNR.png)

   从图中可以看到，大约在25SNR时，BP的Loss就回归正常了，但是当SNR低的时候，Loss非常的高。

3. 训练集数量的影响

   这里依旧取50个主元，无高斯白噪声。

   | 训练集数量 | Traininglossrate | Testinglossrate |
   | ----- | ---------------- | --------------- |
   | 40    | 1                | 0.9917          |
   | 80    | 0.9875           | 0.9813          |
   | 120   | 0.7833           | 0.8536          |
   | 160   | 0.0063           | 0.1417          |
   | 200   | 0.0050           | 0.1500          |
   | 240   | 0.0042           | 0.1188          |
   | 280   | 0.0107           | 0.0833          |
   | 320   | 0.0343           | 0.1375          |
   | 360   | 0.0139           | 0.0750          |

   ![BP分类训练集数量](PCA\BP分类训练集数量.png)

   可以看到，当训练集数量到160时存在一个突变，在此之前此网络的loss很高，之后loss很低。因此可以认为此网络最少需要160个训练样本。

4. 总结

   可以看到，这个BP网络大约只能支持PCA主元数为50，大于50的主元数会带来欠拟合问题。当保持PCA主元数为50时，最多只能容忍约SNR为25db的高斯白噪声，最少需要160个训练样本。

#### 2.2 RBF网络分类

RBF网络的基础知识在上一次已经提到过了，在此就不再赘述了。在这里，使用matlab的神经网络工具箱进行仿真。Label与BP一样采用Onehot编码。

##### 2.2.1 网络参数设置：

RBF分类网络使用newbfe函数进行设计，要对newbfe的扩散系数进行设置，如用默认的1，则分类准确率低于5%。

取PCA50个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为8时，loss最低：

![RBF分类扩散系数影响](PCA\RBF分类扩散系数影响.png)

取PCA500个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为17时，loss最低：

![RBF分类扩散系数影响1](PCA\RBF分类扩散系数影响1.png)

取PCA20个主元，训练集和测试集各用一半进行测试扩散系数对结果的影响，发现取扩散系数为9时，loss最低：

![RBF分类扩散系数影响2](PCA\RBF分类扩散系数影响2.png)



所以，综合上述测试，为了平衡在各种情况下的测试结果，下面测试全部取扩散系数为12。

##### 2.2.2 分类结果

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Trainingloss | Testingloss |
   | ------ | ------------ | ----------- |
   | 2      | 70           | 126         |
   | 5      | 0            | 97          |
   | 7      | 0            | 107         |
   | 10     | 0            | 43          |
   | 15     | 0            | 13          |
   | 20     | 0            | 15          |
   | 25     | 0            | 10          |
   | 30     | 0            | 9           |
   | 40     | 0            | 8           |
   | 50     | 0            | 9           |
   | 60     | 0            | 9           |
   | 80     | 0            | 7           |
   | 150    | 0            | 7           |
   | 200    | 0            | 7           |
   | 500    | 0            | 7           |

   ![RBF分类pca主元](PCA\RBF分类pca主元.png)

   由于RBF网络工具箱会随训练样本的不同调整权置和神经元数目使训练集的误差最低，因此，相比BP网络有更好的表现。这并不是说明BP网络本身性能低于RBF网络，而是因为BP网络的参数多于RBF网络，因此自适应调整有难度，如上面的结果，当BP网络调整得好的时候，结果也是很好的，但需要每次为输入样本调整参数。RBF网络loss的情况来看，在主元数大于15以后，结果就很好，过拟合没有了，而且testloss很低。而且随着主元数的增加，testloss也基本没有起伏。

2. 高斯白噪声的影响：

   训练集与测试集各一半，即用200张训练，200张测试，PCA主元取50个。分类结果如下表：

   | 高斯白噪声(SNR) | Trainingloss | Testingloss |
   | ---------- | ------------ | ----------- |
   | 2          | 0            | 195         |
   | 5          | 0            | 192         |
   | 7          | 0            | 124         |
   | 10         | 0            | 21          |
   | 15         | 0            | 8           |
   | 20         | 0            | 9           |
   | 25         | 0            | 9           |
   | 30         | 0            | 9           |
   | 40         | 0            | 9           |
   | 50         | 0            | 9           |
   | 60         | 0            | 9           |
   | 80         | 0            | 9           |

   ![RBF分类白噪声](PCA\RBF分类白噪声.png)

   可以看到在50个主元的情况下，在实验中RBF网络都可以保证对训练集完全分类，但是只有当$\text{SNR}\ge 15$时，testloss才开始正常。可以认为在这个情况下，RBF网络可以容忍$\text{SNR}\ge 15$的高斯白噪声。

3. 训练集数量的影响：

   这里依旧取50个主元，无高斯白噪声。

   | 训练集数量 | Traininglossrate | Testinglossrate |
   | ----- | ---------------- | --------------- |
   | 40    | 0                | 0.3806          |
   | 80    | 0                | 0.2281          |
   | 120   | 0                | 0.1321          |
   | 160   | 0                | 0.0917          |
   | 200   | 0                | 0.0800          |
   | 240   | 0                | 0.0500          |
   | 280   | 0                | 0.0417          |
   | 320   | 0                | 0.0375          |
   | 360   | 0                | 0.0500          |

   ![RBF分类训练集数量](PCA\RBF分类训练集数量.png)

   在这里我们看到，当训练样本为160个的时候，RBF网络的testloss下降率的变化率发生了变化，同时，此时的测试集正确率大于90%，因此认为在训练集大于160个的时候此网络误差就在可容许的范围内。

   ​

#### 2.3 SVM分类

##### 2.2.1 网络参数设置：

由于matlab本身自带的工具箱中的SVM并不能直接用于多分类系统，虽然也可以手动改为用softmax回归或者投票机制的多分类器，但是最终实验下来效果都不够理想，准确率都不能超过30%。因此最终使用了第三方的svm工具箱，libsvm。同时，由于libsvm中的SVM函数svmtrain与svmpredict都与matlab自带工具箱重名，因此将libsvm中的函数改为svmtrain2与svmpredict2。

使用的svm分类器使用默认参数。即是使用高斯核，C-SVC，gamma取1。因为默认参数的效果已经足够好了，因此不再调试参数，直接仿真。

##### 2.2.2 分类结果

由于这里使用的是高斯核函数，分类时总是可以达到对训练集的完美分类，因此，这里不列出trainingloss。

1. PCA主元数的影响：

   这里，训练集与测试集各一半，即用200张训练，200张测试。分类结果如下表：

   | PCA主元数 | Testingloss |
   | ------ | ----------- |
   | 2      | 134         |
   | 5      | 53          |
   | 7      | 44          |
   | 10     | 36          |
   | 15     | 34          |
   | 20     | 30          |
   | 25     | 23          |
   | 30     | 19          |
   | 40     | 15          |
   | 50     | 11          |
   | 60     | 10          |
   | 80     | 8           |
   | 150    | 8           |
   | 200    | 9           |
   | 500    | 16          |

   ![SVMpca主元](PCA\SVMpca主元.png)

   可以看到，SVM在25个主元时，testloss降低到了20左右，在并在80个主元时达到最低，但总体来说，SVM在主元更少的时候的表现要好于RBF网络与BP网络。但当主元数逐渐增加，似乎又出现了过拟合的情况。

2. 高斯白噪声的影响：

   训练集与测试集各一半，即用200张训练，200张测试，PCA主元取50个。分类结果如下表：

   | SNR(db) | Testingloss |
   | ------- | ----------- |
   | 2       | 156         |
   | 5       | 127         |
   | 7       | 71          |
   | 10      | 54          |
   | 15      | 27          |
   | 20      | 13          |
   | 25      | 12          |
   | 30      | 12          |
   | 40      | 11          |
   | 50      | 11          |
   | 60      | 11          |
   | 80      | 11          |

   ![SVMpcaSNR](PCA\SVMpcaSNR.png)

   可以看到，$\text{SNR}\ge20$时，SVM的loss回归正常水平，大约在15db时，loss也还可以接受。对噪声的抑制要好于BP网络，但略逊色于RBF网络。

3. 训练集数量的影响：

   | 训练集数 | Testinglossrate |
   | ---- | --------------- |
   | 40   | 0.2750          |
   | 80   | 0.3500          |
   | 120  | 0.3536          |
   | 160  | 0.2625          |
   | 200  | 0.2300          |
   | 240  | 0.1500          |
   | 280  | 0.1083          |
   | 320  | 0.0875          |
   | 360  | 0.0500          |

   ![SVMpca训练集](PCA\SVMpca训练集.png)

   相比较前两者，SVM少量训练样本时的表现比BP网络和RBF网络更好。

### 3. 总结

可以看到这三种分类器在合适的参数下，用PCA进行特征提取以后，都可以很好的完成分类目标，下面就从三方面分别讨这三者的优劣。

#### 3.1 PCA主元数影响

以错误降到20个左右进行划分（此时相当于90%正确率。）列出下表

| BP   | RBF  | SVM  |
| ---- | ---- | ---- |
| 20   | 15   | 25   |

由此来看，RBF表现最好，BP其次，但是，实际上，根据全表可以看到，SVM在主元数少的时候，loss要小于另两者，而BP由于网络并未根据情况进行调整，而是一直用同一网络，因此，其结果也不具有太大的代表性，但总的来说，就方法的普适性和运行速度来说，RBF和SVM要优于BP。但是就从性能上来说，可以看到，这三者在分类效果最优时，性能差矩不大。

总的来说，SVM在主元少的时候就可以有优秀的表现，但当前的参数设置随着主元数升高，正确率提高不如另两者快。RBF可以最快达到90%正确率，但是这是由于其网络结构会根据样本分布和数量自适应调整的结果，这个优秀的结果是好的参数+方法得到的，并不能单纯的说RBF就适合于分类。而BP则是最不稳定的，在实测中，也常常有BP网络训练时陷入某个局部极小而使得loss突然增大，但当参数合适时，也可达到另两者的性能。

#### 3.2 高斯白噪声的影响

以错误降到20个左右进行划分，列出下表：

| BP   | RBF  | SVM  |
| ---- | ---- | ---- |
| 25   | 10   | 15   |

可以看到，抗噪能力上，RBF的表现也是最好的，而SVM也差不多。但是从BP的趋势图可以看到，在SNR25db处有突变即突然分类效果就回归正常了，而RBF随SNR增加，loss减少的最快，SVM的loss减少的也很快，但是不如RBF快。因此，在这个问题上，可以认为，RBF网络的抗噪能力是最好的。但是，同时比较噪声极大的时候，SVM的正确率也是高于另两者的，说明SVM在极大噪声情况下，表现要好于另两者。

#### 3.3 训练集数量的影响

以错误率降到0.1左右进行划分，列出下表：

| BP   | RBF  | SVM  |
| ---- | ---- | ---- |
| 200  | 120  | 240  |

可以看到，RBF所需要的训练样本数更少，BP其次，SVM最多。但是SVM在10%训练集时就可以达到很好的效果，这一点是比另两者要优秀的。

#### 3.4 总结

综上，三种方法在参数足够好的情况下都可以达到很好的分类效果。RBF由于其网络结构会根据样本分布和数量自适应调整以达到最小误差，所以有最优秀的表现。BP由于其参数过多，本身难以调整，再加上迭代和局部最小等问题，其调整难度是最大的，而且每次训练的结果不稳定。SVM则相比更中庸但稳定，同时，SVM在少样本，大噪声，少主元等极端情况下的表现最好。



## 三、ICA信号分离

1. 将三幅图像混合在一起，得到三幅混合后的图像，分别采用三种不同的ICA方法进行图像恢复，并讨论分析。
2. 将三幅图像混合在一起，得到四幅混合后的图像，分别采用三种不同的ICA方法进行图像恢复，并与题一得到的结果进行比较
3. 将三个语音信号进混合在一起，得到三个混合后的语音信号，分别采用三种不同的ICA方法进行信号恢复，并讨论分析。
4. 将三个语音信号进混合在一起，得到四个混合后的语音信号，分别采用三种不同的ICA方法进行信号恢复，并与题三得到的结果进行比较。

由于上述四题都为ICA分离信号的问题，因此将它们合并在一起报告。

### 1. 基础知识

对于混合的信号，如果各信号独立，且如果在众多信号中，最多有一个分布为高斯分布的数据信号，我们可以使用独立元分析的方法将原信号进行解混。解混的思路就是使用各种方法（如统计特性、神经网络的负反馈等）使输出数据的独立性达到最大，此时就可以恢复出混合之前的信号，但是，恢复后的信号，在幅度和顺序上是随机的。

ICA主要分为两类方法：非目标函数和有目标函数的，分类主要如下

| 非目标函数   | 有目标函数   |
| ------- | ------- |
| H-J方法   | 最大熵法    |
| 四阶统计量方法 | 最小互信息法  |
| -       | 负熵法     |
| -       | FastICA |

然后，本次使用的方法为H-J方法、四阶统计量方法、最大熵法和FastICA法。

#### 1.1 H-J方法

H-J方法的核心是利用独立的定理：当$x$与$y$独立时，$E(f(x)g(y))=E(f(x))E(g(y))$，$f,g$为任意的函数。

其主要流程如下：

![H-J](ICA\报告用图\H-J.png)

$s_i$为源信号，$\mathbf{A}$为混合矩阵，$x_i$为混合后的信号，$\mathbf{W}$是$x_i$混合混阵，$y_i$是混合以后得到的值。它们的关系是：
$$
\mathbf{y}=\mathbf{x}-\mathbf{Wy}\\
\mathbf{x}=(I+\mathbf{W})\mathbf{y}\\
\mathbf{y}=(I+\mathbf{W})^{-1}\mathbf{x}
$$
权值的调整公式为：
$$
\frac{d\mathbf{w}}{dt}=\eta\mathbf{f(y)g(y)}\\
or\\
\frac{d\mathbf{w}}{dt}=\eta(I-\mathbf{f(y)g(y)})
$$
当$f(\cdot),g(\cdot)$为奇函数，当$\mathbf{y}$内部的各变量互相独立时，有$\frac{d\mathbf{w}}{dt}=0$。

其方法的步骤为：

1. 初始化权值$
2. 算出$\frac{d\mathbf{w}}{dt}$
3. 调整权值直到$\mathbf{w}$不变。
4. 得到分离后的信号$\mathbf{y}$

#### 1.2 白化

由于后面的方法都会用到白化处理，因此在这里先介绍一下什么是白化。

白化本质上是一个单位方差的PCA处理。

将每一路信号表示为$\mathbf{x}_i,i=1,2,\ldots,m$，$m$为观察到的信号的数量，源表示为$\mathbf{s}_i,i=1,2,\ldots,n$，则对$\mathbf{x}_i$的集合作协方差得到协方差矩阵$\mathbf{C}_x$，它的特征值按从大到小排序为$\lambda_1,\lambda_2,\ldots,\lambda_m$，对应的特征向量为$\mathbf{u}_1,\mathbf{u}_2,\ldots,\mathbf{u}_m$。对协方差矩阵进行SVD分解：
$$
\mathbf{C}_x=[\mathbf{u}_1,\mathbf{u}_2,\ldots,\mathbf{u}_m]diag(\lambda_1,\ldots,\lambda_m)[\mathbf{u}_1,\mathbf{u}_2,\ldots,\mathbf{u}_m]^T
$$
若$s_i$互相都是独立的，则所有特征值中，前n个特征值非零，若样本是无噪的，则后$m-n$个特征值为0，若有噪声，其方差为$\delta^2$，则后$m-n$个特征值为$\delta^2$。

那么由此就可从混合信号中观察到源信号的个数。

所以定义白化矩阵：
$$
\mathbf{M}=diag(\frac{1}{\sqrt{\lambda_1}},\frac{1}{\sqrt{\lambda_2}},\ldots,\frac{1}{\sqrt{\lambda_n}})[\mathbf{u}_1,\mathbf{u}_2,\ldots,\mathbf{u}_n]^T
$$
则白化过程即是混合后的信号左乘白化矩阵：
$$
\mathbf{z}=\mathbf{M}\mathbf{x}
$$
$\mathbf{z}$是白化后的信号。所以当源的数量与观察信号数量不一致，但方法要求他们一致时可以先白化再处理。

整个算法流程可以表示如下：

1. 将观察到的信号向量移除均值。


1. 求取协方差矩阵的特征值，并确定源的个数
2. 求取白化矩阵并白化观察信号，得到$\mathbf{z}$

由于实际过程中，样本总是带噪声的，因此对于白化过程的噪声方差要由先验知识进行调整。

#### 1.3 四阶统计量方法

该方法同样是无目标函数的ICA算法。其核心证明过程即是用四阶矩可以得到如下关系：
$$
\mathbf{A}=\mathbf{M}^{-1}\mathbf{B}   \\
\mathbf{s}=\mathbf{B}^T\mathbf{z}\\
$$
其中，$\mathbf{B}$为白化后信号$\mathbf{z}$的四阶矩的特征向量组成的矩阵 ，可由SVD分解得到。

流程为：

1. 先将观察的信号白化
2. 求白化后信号的四阶矩，进行SVD分解，得到特征向量组成的矩阵B。
3. 源信号即是$\mathbf{s}=\mathbf{B}^T\mathbf{x}$

#### 1.4 最大熵方法

这是一个有目标函数的ICA算法，利用信号独立时，信息熵最大这一性质，定义：
$$
y_i = f(u_i)\\
f(u_i)=\frac{1}{1+e ^{-u_i}}\\
u_i = \sum_{j=1}^mw_{i,j}x_j
$$
则向量$\mathbf{y}$的熵定义为：
$$
H(\mathbf{y})=-\int P_y(\mathbf{y})\log P_y(\mathbf{y})d\mathbf{y} = -E(\log P_y(\mathbf{y}))
$$
$P_y(\mathbf{y})$为概率密度函数。

则权值的调整公式即为：
$$
\Delta \mathbf{W}=\eta \frac{\partial H(\mathbf{y})}{\partial \mathbf{W}}=\eta((\mathbf{W}^T)^{-1}+(\mathbf{1}-2\mathbf{y}))
$$
$\mathbf{1}$为全1的向量。

其步骤为：

1. 初始化权值，随机选取$\mathbf{W}$
2. 算出$\mathbf{y}$。
3. 算出$\Delta \mathbf{W}$
4. 迭代直到$\Delta\mathbf{W}$不再变化。

#### 1.5 FASTICA方法

FastICA是有目标函数的ICA算法.

考虑单一神经元，令$\mathbf{x}$为白化后的零均值向量$\mathbf{z}$的样本，输入到该神经元。我们制定的基本学习规则为：“在神经元权值$\mathbf{w}$取$\Vert\mathbf{w}\Vert=1$的约束下，最大化$\mathbf{w}$对随机向量$\mathbf{z}$投影的负熵“，在该原则下，其目标函数是：
$$
F =E\{G_2(\mathbf{w}^T\mathbf{z})\}+\frac{1}{2}\beta\Vert \mathbf{w} \Vert
$$
权值调整公式为：
$$
\mathbf{w}_i(t)=E\{g_2(\mathbf{w}_i^T(t-1)\mathbf{z})\mathbf{z}  \}-E\{ g_2(\mathbf{w}_i^T(t-1)\mathbf{z}) \}\mathbf{w}_i(t-1)
$$
$G_2(\cdot)$是偶函数，一般取：
$$
G_2(y)=\frac{1}{a}\log(\cosh(ay)),a\in[1,2]\\
or\\
G_2(y)=-\exp(-\frac{y^2}{2})
\\
g_2(y)=\frac{\partial G_2(y)}{\partial y}\\
g_2(y)=a(1-\tanh^2(ay)),a\in[1,2]\\
g_2(y)=(1-y^2)\exp(-\frac{y^2}{2})
$$
其步骤为：

1. 对样本进行白化
2. 随机初始化神经元权值$\mathbf{w}_i(0)$并归一化
3. 计算$g_2(y)$并根据上述公式得到下一步的$\mathbf{w_i}(t)$并归一化
4. 正交化$\mathbf{w}_i(t)$
5. 如果$\mathbf{w}_i$不收敛，回到3。

### 2. 仿真方法

#### 2.1 分布分析

采用以上四种方法对图像的混合以及音频的混合结果进行解混。由于ICA要求只能有一个高斯分布，因此，先对信号进行四阶累积量分析：

| 图像   | 1        | 2         | 3        | 4         |
| ---- | -------- | --------- | -------- | --------- |
| kurt | 9.47e+06 | -9.34e+06 | 1.40e+06 | -4.33e+06 |

则图像信号为两个超高斯，两个亚高斯分布

![1](ICA\风景图\1.bmp)

![2](ICA\风景图\2.bmp)

![3](ICA\风景图\3.bmp)

![4](ICA\风景图\4.bmp)

声音信号的四阶累计量普遍较小，可能和声音信号读取的时候进行了归一化有关，我们一般认为声音信号属于超高斯信号。

#### 2.2 解混的评价标准

对于图片，我们可以用之前用过的PSNR作为判断依据，同时，比较两个序列的相近程度，我们可以用皮尔逊相关系数来进行评价：
$$
r(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}
$$
$Cov(\cdot)$是协方差，$Var(\cdot)$是方差。

当$r$越靠近1，则两者相关程度越大，信号也越相近。

因此用PSNR和相关系数作为评价标准。

#### 2.3 源信号的选取

本次仿真对于图片混合是从四张图中**随机选取三张图片**进行混合。对于音频信号，由于经过实验，不同种类的音频信号，长度与采样率都不同，混合时可能会出现问题，为了实验便利性考虑，**只使用同一类的音频**进行混合（实际实验中只使用了music类型的音频）。混合矩阵是随机产生并归一化过的。



### 3.信号分离效果：

#### 3.1 问题1的结果（3幅图混3幅图）

##### 3.1.1 H-J方法结果：

混合后的图：

![mix3](ICA\result\3-3\hj\mix3.bmp)

![mix2](ICA\result\3-3\hj\mix1.bmp)

![mix2](ICA\result\3-3\hj\mix2.bmp)

分离后的图像：

![1](ICA\result\3-3\hj\1.bmp)

![2](ICA\result\3-3\hj\2.bmp)

![3](ICA\result\3-3\hj\3.bmp)

可以看到，分离以后图的次序变成了3 1 2。

PSNR结果：

| 源图像     | 1     | 2     | 3     |
| ------- | ----- | ----- | ----- |
| PSNR/db | 18.46 | 21.63 | 18.13 |

相关系数的结果：

| 源图像/输出次序 | 1       | 2       | 3       |
| -------- | ------- | ------- | ------- |
| 1        | -0.2026 | -0.2080 | 0.9387  |
| 2        | 0.8385  | -0.4400 | -0.1544 |
| 3        | -0.1145 | 0.9568  | -0.2818 |

| 源图像/混合图像 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.1231 | 0.9825 | 0.1520 |
| 2        | 0.6682 | 0.3846 | 0.7088 |
| 3        | 0.5550 | 0.8150 | 0.2940 |

可以看到H-J的效果从肉眼观察并不好，但是其相关系数结果来看，还是将三幅图基本分开了，相比较混合图像，相关系数矩阵更集中了。同时，也可以用相关系数矩阵来辩别位置。

##### 3.1.2 四阶矩方法结果：

混合结果：

![mix1](ICA\result\3-3\r4\mix1.bmp)

![mix2](ICA\result\3-3\r4\mix2.bmp)

![mix3](ICA\result\3-3\r4\mix3.bmp)

分离结果：

![1](ICA\result\3-3\r4\1.bmp)

![3](ICA\result\3-3\r4\3.bmp)

![5](ICA\result\3-3\r4\5.bmp)

可以看到，分离以后图的次序变成了1 4 3。

PSNR结果：

| 源图像     | 1     | 3     | 4     |
| ------- | ----- | ----- | ----- |
| PSNR/db | 29.98 | 23.56 | 28.43 |

相关系数的结果：

| 源图像/输出次序 | 1       | 3       | 4      |
| -------- | ------- | ------- | ------ |
| 1        | 0.9776  | -0.0622 | 0.1141 |
| 2        | -0.1586 | -0.1737 | 0.9865 |
| 3        | 0.1379  | 0.9828  | 0.1171 |

| 源图像/混合图像 | 1      | 3      | 4      |
| -------- | ------ | ------ | ------ |
| 1        | 0.4436 | 0.9140 | 0.1354 |
| 2        | 0.6844 | 0.7078 | 0.2875 |
| 3        | 0.5102 | 0.5640 | 0.6416 |

从肉眼观察结果来看四阶矩效果比H-J要好很多，几乎看不到被混合的样子。从相关系数和PSNR也可以看出来，四阶矩方法要好于H-J。

##### 3.1.3 最大熵方法结果：

混合结果：

![mix1](ICA\result\3-3\maxh\mix1.bmp)

![mix2](ICA\result\3-3\maxh\mix2.bmp)

![mix3](ICA\result\3-3\maxh\mix3.bmp)

分离结果：

![1](ICA\result\3-3\maxh\1.bmp)

![3](ICA\result\3-3\maxh\3.bmp)

![5](ICA\result\3-3\maxh\5.bmp)

可以看到，图片的顺序变为了2 3 4。

PSNR结果：

| 源图像     | 2     | 3     | 4     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 11.33 | 28.43 | 23.56 |

相关系数的结果：

| 源图像/输出次序 | 2       | 3      | 4       |
| -------- | ------- | ------ | ------- |
| 1        | 0.9745  | 0.1633 | 0.1130  |
| 2        | -0.1713 | 0.9800 | -0.1966 |
| 3        | -0.1449 | 0.1138 | 0.9739  |

| 源图像/混合图像 | 2      | 3      | 4      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6331 | 0.7050 | 0.2368 |
| 2        | 0.2979 | 0.9261 | 0.1390 |
| 3        | 0.8452 | 0.2757 | 0.4268 |

最大熵方法的效果看起来相比较四阶矩要差一些，但是相比较H-J要好一些。

##### 3.1.4 FASTICA方法

混合后图片：

![mix1](ICA\result\3-3\FASTICA\mix1.bmp)

![mix2](ICA\result\3-3\FASTICA\mix2.bmp)

![mix3](ICA\result\3-3\FASTICA\mix3.bmp)

分离后结果：

![1](ICA\result\3-3\FASTICA\1.bmp)

![3](ICA\result\3-3\FASTICA\3.bmp)

![5](ICA\result\3-3\FASTICA\5.bmp)

输出图顺序为：1 3 2

PSNR结果：

| 源图像     | 1     | 2     | 3     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 32.61 | 43.94 | 38.11 |

相关系数的结果：

| 源图像/输出次序 | 2      | 3       | 4       |
| -------- | ------ | ------- | ------- |
| 1        | 0.9884 | -0.0358 | -0.0228 |
| 2        | 0.1265 | -0.0054 | 0.9995  |
| 3        | 0.0850 | 0.9993  | -0.0206 |

| 源图像/混合图像 | 2      | 3      | 4      |
| -------- | ------ | ------ | ------ |
| 1        | 0.1231 | 0.9825 | 0.1520 |
| 2        | 0.6682 | 0.3846 | 0.7088 |
| 3        | 0.5550 | 0.8150 | 0.2940 |

FastICA效果可以看到和四阶矩一样，非常优秀，肉眼完全看不到混合。从相关系数和PSNR来看，FastICA效果甚至要好于四阶矩。

##### 3.1.5 小结

从上面来看，效果为：
$$
\text{FASTICA}>\text{四阶矩}\gg \text{最大熵}>\text{H-J}
$$
前两者用肉眼几乎看不出区别，后两者则能看出还有信号混合的迹像。



#### 3.2 问题二的结果（4幅分3幅）

此问题的一个重点在于，像H-J和最大熵要求输入信号和源信号数目要相等，则要在输入算法前先将输入变量白化。

##### 3.2.1 H-J算法效果

混合图像：

![mix1](ICA\result\4-3\hj\mix1.bmp)

![mix2](ICA\result\4-3\hj\mix2.bmp)

![mix3](ICA\result\4-3\hj\mix3.bmp)

![mix4](ICA\result\4-3\hj\mix4.bmp)

分离效果：

![1](ICA\result\4-3\hj\1.bmp)

![2](ICA\result\4-3\hj\2.bmp)

![3](ICA\result\4-3\hj\3.bmp)

输出图像顺序：4 2 3

PSNR结果：

| 源图像     | 2     | 3     | 4     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 15.24 | 16.62 | 20.65 |

相关系数的结果：

| 源图像/输出次序 | 2       | 3       | 4       |
| -------- | ------- | ------- | ------- |
| 1        | -0.2991 | -0.0709 | 0.9523  |
| 2        | 0.8215  | 0.2961  | -0.4908 |
| 3        | -0.5007 | 0.8307  | -0.3344 |

| 源图像/混合图像 | 2      | 3      | 4      |
| -------- | ------ | ------ | ------ |
| 1        | 0.5428 | 0.4789 | 0.6490 |
| 2        | 0.8460 | 0.4991 | 0.0838 |
| 3        | 0.6355 | 0.5227 | 0.5194 |
| 4        | 0.4859 | 0.8406 | 0.1367 |

可以看到，H-J出来的结果这次比较差，主要原因是因为迭代也没有收敛。但是从相关系数的表现来说，我们可以看到分离还是有成效的。

##### 3.2.2 四阶矩方法

混合图像：

![mix1](ICA\result\4-3\r4\mix1.bmp)

![mix2](ICA\result\4-3\r4\mix2.bmp)

![mix3](ICA\result\4-3\r4\mix3.bmp)

![mix4](ICA\result\4-3\r4\mix4.bmp)

分离图像：

![2](ICA\result\4-3\r4\2.bmp)

![3](ICA\result\4-3\r4\3.bmp)

![4](ICA\result\4-3\r4\4.bmp)

输出图片顺序为：4 3 1

PSNR结果：

| 源图像     | 1     | 3     | 4     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 29.98 | 28.43 | 23.56 |

相关系数的结果：

| 源图像/输出次序 | 1       | 3       | 4      |
| -------- | ------- | ------- | ------ |
| 1        | -0.1586 | -0.1737 | 0.9865 |
| 2        | 0.1379  | 0.9828  | 0.1171 |
| 3        | 0.9776  | -0.0622 | 0.1141 |

| 源图像/混合图像 | 1      | 3      | 4      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6509 | 0.3240 | 0.6775 |
| 2        | 0.8354 | 0.3642 | 0.4305 |
| 3        | 0.1581 | 0.1876 | 0.9550 |
| 4        | 0.4931 | 0.8174 | 0.3409 |

可以看到，当四阶矩的效果还是一如既往的好。依旧是用肉眼无法看到混叠的效果。

##### 3.2.3 最大熵方法

混合图像：

![mix1](ICA\result\4-3\maxh\mix1.bmp)

![mix2](ICA\result\4-3\maxh\mix2.bmp)

![mix3](ICA\result\4-3\maxh\mix3.bmp)

![mix4](ICA\result\4-3\maxh\mix4.bmp)

分离效果：

![1](ICA\result\4-3\maxh\1.bmp)

![3](ICA\result\4-3\maxh\3.bmp)

![5](ICA\result\4-3\maxh\5.bmp)

输出图像顺序为：2 3 1

PSNR结果：

| 源图像     | 1     | 2     | 3     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 27.89 | 17.07 | 15.97 |

相关系数的结果：

| 源图像/输出次序 | 1       | 2       | 3      |
| -------- | ------- | ------- | ------ |
| 1        | -0.0155 | 0.8819  | 0.4370 |
| 2        | -0.2554 | -0.4676 | 0.8354 |
| 3        | 0.9667  | -0.0597 | 0.3333 |

| 源图像/混合图像 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.1573 | 0.2110 | 0.9707 |
| 2        | 0.3992 | 0.5177 | 0.7904 |
| 3        | 0.3793 | 0.3681 | 0.8797 |
| 4        | 0.3118 | 0.8116 | 0.5213 |

最大熵方法的在这个场景下不尽如人意，主要原因也是因为迭代了没收敛。

##### 3.2.4 FASTICA方法

混合图像：

![mix1](ICA\result\4-3\FASTICA\mix1.bmp)

![mix2](ICA\result\4-3\FASTICA\mix2.bmp)

![mix3](ICA\result\4-3\FASTICA\mix3.bmp)

![mix4](ICA\result\4-3\FASTICA\mix4.bmp)

分离结果：

![1](ICA\result\4-3\FASTICA\4.bmp)

![2](ICA\result\4-3\FASTICA\2.bmp)

![3](ICA\result\4-3\FASTICA\6.bmp)

输出顺序为1 3 2

PSNR结果：

| 源图像     | 1     | 2     | 3     |
| ------- | :---- | ----- | ----- |
| PSNR/db | 32.61 | 36.35 | 38.04 |

相关系数的结果：

| 源图像/输出次序 | 1      | 2       | 3       |
| -------- | ------ | ------- | ------- |
| 1        | 0.9884 | -0.0358 | -0.0228 |
| 2        | 0.1296 | 0.0317  | 0.9980  |
| 3        | 0.0799 | 0.9988  | -0.0589 |

| 源图像/混合图像 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6092 | 0.6072 | 0.5839 |
| 2        | 0.6352 | 0.5301 | 0.6349 |
| 3        | 0.9848 | 0.2140 | 0.1415 |
| 4        | 0.4581 | 0.7790 | 0.4858 |

FASTICA效果也和之前一样好，完全看不出混叠。

##### 3.2.5 小结

从上面来看，效果为：
$$
\text{FASTICA}>\text{四阶矩}\gg \text{最大熵}\approx \text{H-J}
$$
前两者用肉眼几乎看不出区别，后两者则能看出还有信号混合的迹像。

而且相比较三幅图的结果，FASTICA和四阶矩基本没有什么变化，但是H-J和最大熵的效果变得更差了，这主要是因为相比较三幅图，四幅图白化后的结果更难以收敛，而实际计算当中，两者都设置了迭代上限，往往都是超过上限还无法收敛。



#### 3.3 第三问的结果（3声音分3声音）

声音文件存于ICA/result文件夹中，由于从声音波形也很难看出结果，因此主要观察相关系数。

源声音：

![源文件](ICA\报告用图\源文件.png)

##### 3.3.1 H-J 算法

混合信号：

![混合](ICA\result\audio3-3\hj\混合.png)

分离信号：

![分离](ICA\result\audio3-3\hj\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1      | 2       | 3       |
| -------- | ------ | ------- | ------- |
| 1        | 0.9911 | 0.0368  | -0.1275 |
| 2        | 0.1217 | 0.2882  | 0.9504  |
| 3        | 0.0797 | -0.9325 | 0.3504  |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6557 | 0.0989 | 0.7484 |
| 2        | 0.6951 | 0.0143 | 0.7186 |
| 3        | 0.6155 | 0.2626 | 0.7430 |

可以看到出现了负相关，但是声音听起来是没有影响的，主要是因为反相不影响声音的频谱。但是听起来，H-J并没有把声音很好的分离，仍能听到一些其他文件的声音。

##### 3.3.2 四阶矩方法

混合信号：

![混合](ICA\result\audio3-3\r4\混合.png)

分离信号：

![分离](ICA\result\audio3-3\r4\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1       | 2       | 3       |
| -------- | ------- | ------- | ------- |
| 1        | 0.9988  | 0.0043  | 0.0478  |
| 2        | -0.0480 | -0.0098 | 0.9988  |
| 3        | 0.0079  | -0.9999 | -0.0123 |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.7079 | 0.0647 | 0.7031 |
| 2        | 0.8734 | 0.2162 | 0.4354 |
| 3        | 0.1686 | 0.0434 | 0.9848 |

四阶矩的结果相比较H-J有了巨大的提高，可以看到相关系数也都达到0.99以上，同时听起来完全听不见其他文件的声音

##### 3.3.3 最大熵方法

混合信号：

![混合](ICA\result\audio3-3\maxh\混合.png)

分离信号：

![分离](ICA\result\audio3-3\maxh\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1       | 2       | 3       |
| -------- | ------- | ------- | ------- |
| 1        | 0.4704  | 0.8567  | 0.2076  |
| 2        | -0.8163 | 0.5142  | -0.2664 |
| 3        | -0.3351 | -0.0405 | 0.9412  |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6860 | 0.0610 | 0.7248 |
| 2        | 0.8875 | 0.4156 | 0.1941 |
| 3        | 0.1712 | 0.1445 | 0.9749 |

最大熵方法的效果和H-J相差不多。听起来声音仍是混的，相关系数也都没有达到0.99。

##### 3.3.4 FASTICA方法

混合信号：

![混合](ICA\result\audio3-3\fastica\混合.png)

分离信号：

![分离](ICA\result\audio3-3\fastica\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1      | 2       | 3       |
| -------- | ------ | ------- | ------- |
| 1        | 0.0114 | 0.0040  | -0.9999 |
| 2        | 0.0050 | -1.0000 | -0.0069 |
| 3        | 0.9999 | 0.0019  | 0.0113  |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6793 | 0.1437 | 0.7194 |
| 2        | 0.7219 | 0.2396 | 0.6488 |
| 3        | 0.4879 | 0.0733 | 0.8698 |

FASTICA效果非常优秀，可以看到相关系数全是0.9999以上，同时，听起来也完全没有其他声音混合的效果。

##### 3.3.5 小结

从上面来看，效果为：
$$
\text{FASTICA}>\text{四阶矩}\gg \text{最大熵}\approx \text{H-J}
$$
前两者听不出其他声音混合，后两者则能听出还有信号混合的迹像。同时，因为相关系数上FASTICA表现好于四阶矩，因此认为FASTICA效果更好。

#### 3.4 第四题结果 （4声音取3声音）

##### 3.4.1 H-J算法效果

混合信号：

![混合](ICA\result\audio4-3\hj\混合.png)

分离信号：

![分离](ICA\result\audio4-3\hj\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1       | 2       | 3       |
| -------- | ------- | ------- | ------- |
| 1        | 0.0608  | -0.9800 | 0.1877  |
| 2        | -0.1888 | -0.9626 | 0.1888  |
| 3        | 0.0717  | 0.9464  | -0.3118 |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.6557 | 0.0989 | 0.7484 |
| 2        | 0.6951 | 0.0143 | 0.7186 |
| 3        | 0.6155 | 0.2626 | 0.7430 |
| 4        | 0.6936 | 0.0805 | 0.7156 |

H-J在这里的效果变得非常非常差，可以看到相关系数集中同一列了，说明H-J完全没有收敛。听起来的效果也是三个分开的文件听起来一样。

##### 3.4.2 四阶矩方法

混合信号：

![混合](ICA\result\audio4-3\r4\混合.png)

分离信号：

![分离](ICA\result\audio4-3\r4\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1      | 2       | 3       |
| -------- | ------ | ------- | ------- |
| 1        | 0.9988 | 0.0043  | 0.0478  |
| 2        | 0.0480 | 0.0098  | -0.9988 |
| 3        | 0.0079 | -0.9999 | -0.0123 |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.4503 | 0.0971 | 0.8876 |
| 2        | 0.8911 | 0.0855 | 0.4451 |
| 3        | 0.0044 | 0.9741 | 0.2286 |
| 4        | 0.9305 | 0.1241 | 0.3437 |

四阶矩方法的效果还是一样的好，没有听出声音混合的迹象。相关系数也还是和之前一样，都在0.99以上。

##### 3.4.3 最大熵方法

混合信号：

![混合](ICA\result\audio4-3\maxh\混合.png)

分离信号：

![分离](ICA\result\audio4-3\maxh\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1       | 2       | 3       |
| -------- | ------- | ------- | ------- |
| 1        | -0.2344 | -0.9229 | -0.3057 |
| 2        | 0.6064  | -0.3846 | 0.6958  |
| 3        | 0.7598  | 0.0182  | -0.6500 |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.8757 | 0.0282 | 0.4817 |
| 2        | 0.9551 | 0.0206 | 0.2952 |
| 3        | 0.7783 | 0.0892 | 0.6213 |
| 4        | 0.0717 | 0.1664 | 0.9839 |

最大熵的效果也很差，可以看到除了第一个输出，后两个输出基本是1和3的混合，还是没有被分离。听起来也和这里的结果一样。

##### 3.4.4 FASTICA方法

混合信号：

![混合](ICA\result\audio4-3\fastica\混合.png)

分离信号：

![分离](ICA\result\audio4-3\fastica\分离.png)

相关系数的结果：

| 源声音/输出次序 | 1       | 2       | 3      |
| -------- | ------- | ------- | ------ |
| 1        | -0.0114 | -0.0040 | 0.9999 |
| 2        | -0.0050 | 1.0000  | 0.0069 |
| 3        | 0.9999  | 0.0019  | 0.0113 |

| 源声音/混合声音 | 1      | 2      | 3      |
| -------- | ------ | ------ | ------ |
| 1        | 0.9283 | 0.2622 | 0.2612 |
| 2        | 0.7517 | 0.1896 | 0.6313 |
| 3        | 0.2396 | 0.0420 | 0.9700 |
| 4        | 0.7649 | 0.0642 | 0.6407 |

FASTICA的效果和之前一样，非常好，相关系数都在0.9999以上，而且听不出混叠的声音。

##### 3.4.5 小结

从上面来看，效果为：
$$
\text{FASTICA}>\text{四阶矩}\gg \text{最大熵}\approx \text{H-J}
$$
前两者听不出其他声音混合，后两者则在这个情况下几乎没能分离信号。同时，因为相关系数上FASTICA表现好于四阶矩，因此认为FASTICA效果更好。



### 4. 总结

从上面四个问题的仿真结果来看，四种方法的效果是：
$$
\text{FASTICA}>\text{四阶矩}\gg \text{最大熵}\approx \text{H-J}
$$
而运行时间则是：
$$
\text{H-J}>\text{最大熵}\gg \text{四阶矩}\approx \text{FASTICA}
$$
可以看到H-J方法和最大熵方法效果都不尽如人意，对于图像分离还好，对于声音分离效果非常不好。同时，H-J和最大熵方法对于观测数大于源信号数的结果都不如两者相等时的结果好。可能是因为两者对于白化后的信号需要更多的迭代次数。同时运算速度上，H-J也要慢上许多。总的来说四阶矩和FASTICA是非常优秀的ICA算法，运行速度快且效果好。而H-J与最大熵则需要更多次数的迭代来取得好最好的效果。





## 四、SOM分类

用SOM对三样目标进行分类，测试集，训练集各占一半。

### 1. 基础知识

自组织映射神经网络， 即Self Organizing Maps (SOM)， 可以对数据进行无监督学习聚类。它的思想很简单，本质上是一种只有输入层--隐藏层的神经网络。隐藏层中的一个节点代表一个需要聚成的类。训练时采用“竞争学习”的方式，每个输入的样例在隐藏层中找到一个和它最匹配的节点，称为它的激活节点，也叫“winning neuron”。紧接着用随机梯度下降法更新激活节点的参数。同时，和激活节点临近的点也根据它们距离激活节点的远近而适当地更新参数。

所以，SOM的一个特点是，隐藏层的节点是有拓扑关系的。这个拓扑关系需要我们确定，如果想要一维的模型，那么隐藏节点依次连成一条线；如果想要二维的拓扑关系，那么就行成一个平面，如下图所示（也叫Kohonen Network）。

![SOM结构](SOM\报告用图\SOM结构.jpg)

既然隐藏层是有拓扑关系的，所以我们也可以说，SOM可以把任意维度的输入离散化到一维或者二维(更高维度的不常见)的离散空间上。Computation layer里面的节点与Input layer的节点是全连接的。

拓扑关系确定后，开始计算过程，大体分成几个部分：

1. 初始化：每个节点随机初始化自己的参数。每个节点的参数个数与Input的维度相同。

2. 对于每一个输入数据，找到与它最相配的节点。假设输入时D维的， 即 $X=\{x_i, i=1,...,D\}$，那么判别函数可以为欧几里得距离：

   ​
   $$
   d_j(x)=\sum_{i=1}^D（x_i-w_{ji}）^2
   $$

3. 找到激活节点I(x)之后，我们也希望更新和它临近的节点。令$S_{ij}$表示节点i和j之间的距离，对于$I(x)$临近的节点，分配给它们一个更新权重：
   $$
   T_{j,I(x)}=exp(-\frac{S_{j,I(x)}^2}{2\sigma^2})
   $$

4. 接着就是更新节点的参数,按照梯度下降法更新：
   $$
   \Delta w_{ji}=\eta(t)\cdot T_{j,I(x)}(t)\cdot(x_i-w_{ji})
   $$
   迭代直到收敛。

### 2. 仿真方法

#### 2.1 样本的选择

本次测试的样本来源于实验室之前采集的人像数据库，之前用于朝向检测算法的，原数据库中有4000多张图片，分人和朝向保存，此次将其作为人像数据库使用，按人分类。所有的图片都被预先处理为$64\times64$大小，图像格式为bmp格式，灰度图。

在实验过程中，选择三个人的图片各70张，35张作为测试集，35张作为训练集，同时为了加快运算速度，在送入分类前，进行了PCA提取主元。

读入BMP格式的图片后，在matlab中是一个$64\times64$的数组，每个位代表对应的像素值，大小从0-255不等，初始权值选择0-1区间内的随机数，为了让权值迭代能对图片特征神经元的选择产生作用，我们需要先对图片进行归一化，并且将矩阵改变为列向量。

### 3. 分类结果

#### 3.1 SOM分类结果

神经元数目取400个($20\times20$)，初始权值取随机数，邻域函数方差选为20，迭代步长设置为0.3，权值迭代次数为1000次。得到结果如下：

![SOM结果](SOM\报告用图\SOM结果.png)

图中显示的是训练之后特征神经元的分布，每一种颜色的点代表某一种类。可以得到87.61%的测试正确率。运行时间为6.5738秒。可以看到结果的分布比较均匀，但0和1和2在下方有一些交叉，这些交叉可能是误差的来源。

#### 3.2 结果的影响因素

##### 3.2.1 网络大小

选择不同的神经元总数对于识别效果也有较大的影响，取平方数，[64,256,900,1600]，迭代步代设置为0.3，得到结果如下：

| 神经元数目 | 准确率    | 耗时/s   |
| ----- | ------ | ------ |
| 144   | 0.4952 | 3.4487 |
| 256   | 0.6190 | 4.2152 |
| 400   | 0.8762 | 6.5738 |
| 900   | 0.8857 | 11.16  |
| 1600  | 0.8857 | 17.11  |

(为了篇幅考虑，只放出两张图)

![SOM结果144](SOM\报告用图\SOM结果144.png)



![SOM结果1600](SOM\报告用图\SOM结果1600.png)

可以看到随着节点数增多，正确率是会上升的，但是存在一个极限，同时，节点数增多，会带另一个问题即是运行时间变长。这是因为神经元数量增多，每个样本占据的区域与其他样本区域的混叠较小。如果神经元分布比较离散（神经元数目较多），则识别率能上升，但是计算量更大了，所以计算时间也会增多。

#### 3.2.2 邻域函数参数影响：

仍然取神经元为400个，步幅为0.3，取方差为[1,3,5,10,20,40,60]。

得到结果如下：

| 方差   | 正确率     | 时间/s   |
| ---- | ------- | ------ |
| 1    | 0.81905 | 7.1986 |
| 3    | 0.80952 | 6.9959 |
| 5    | 0.9048  | 6.5827 |
| 10   | 0.85714 | 6.0542 |
| 20   | 0.87619 | 6.5738 |
| 40   | 0.89524 | 6.3178 |
| 60   | 0.78095 | 6.3285 |

方差为1：

![SOM结果1](SOM\报告用图\SOM结果1.png)

方差为60：

![SOM结果60](SOM\报告用图\SOM结果60.png)

可以看到，在方差取5-40左右，正确率都很高但过高或过低都为影响到正确率，这应该是由于方差影响的是邻域的大小，当方差过大时邻域也很大，会使各样本重叠增大，进而降低正确率。同时，这个对于运行时间的影响不大。

#### 3.2.3 邻域函数参数影响：

仍然取神经元为400个，方差为20，取步幅为[0.1,0.3,0.5,0.7,0.9]。

| 方差   | 正确率     | 时间/s   |
| ---- | ------- | ------ |
| 0.1  | 0.89524 | 6.29   |
| 0.3  | 0.87619 | 6.5738 |
| 0.5  | 0.66667 | 6.3716 |
| 0.7  | 0.8857  | 6.2649 |
| 0.9  | 0.8381  | 6.1592 |

![SOM结果0.1](SOM\报告用图\SOM结果0.1.png)

![SOM结果0.9](SOM\报告用图\SOM结果0.9.png)

可以看到在步长小的时候对结果影响不大，当步长过大，结果会不收敛。



### 3. 总结

综上，取400个神经元，步幅为0.3，方差为5时达到最优准确率，为0.9048。

SOM具有一定的聚类效果和可视化效果，对于人像分类有很好的效果。对于结果，神经元的个数增大，步幅减小，取合适的方差可以取得更好的效果。但是由于初始权值是随机的，因此结果不是完全稳定的。

时间方面，SOM识别的速度主要与迭代次数，神经元数目有关，更多的神经元和更多的迭代次数能增强识别率，但是会增加计算时间，需要根据实际需要均衡两者。